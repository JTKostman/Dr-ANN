MIMIC3 Data:

Description: MIMIC-III is a large, publicly-available database comprising de-identified health-related data associated with approximately sixty thousand admissions of patients who stayed in critical care units of the Beth Israel Deaconess Medical Center between 2001 and 2012. The database includes information such as demographics, vital sign measurements made at the bedside (~1 data point per hour), laboratory test results, procedures, medications, nurse and physician notes, imaging reports, and out-of-hospital mortality. MIMIC supports a diverse range of analytic studies spanning epidemiology, clinical decision-rule improvement, and electronic tool development. It is notable for three factors:
it is publicly and freely available.
it encompasses a diverse and very large population of ICU patients.
it contains high temporal resolution data including lab results, electronic documentation, and bedside monitor trends and waveforms.
MIMIC III is an update to MIMIC II v2.6 and contains the following new classes of data:
approximately 20,000 additional ICU admissions
physician progress notes
medication administration records
more complete demographic information
current procedural terminology (CPT) codes and Diagnosis-Related Group (DRG) codes
The MIMIC III Clinical Database, although de-identified, still contains detailed information regarding the clinical care of patients, and must be treated with appropriate care and respect. Researchers seeking to use the full Clinical Database must formally request access to the MIMIC III Database.

There is two types of data in the mimic database: 

    1.) Static data - data is recorded once for a given identifier. This data does not change over time and does not have an associated timestamp. e.g. date of birth 
    2.) Dynamic data - data changes overtime and has an associated timestamp. e.g. patient blood pressure 

Data Tables: 
Admissions, Callout, Caregivers, Chartevents, CPTevents, D_CPT, D_ICD_Diagnoses, D_ICD_Procedures, D_Items, D_Labitems, Datetimeevents, Diagnoses_ICD, DRGCodes, ICUSTAYS, patients, prescriptions, services, transfers, etc.. More of the datatables can be found here https://mimic.physionet.org/mimicdata/identifiers/ 

Hospital acquired data: If we want the data from the hospital database and info recored in the hospital, but not necessairly during the patient's ICU stay that we want to look at the following tables:
Admissions, callout, cptevents, diagnoses_icd, drgcodes, icustays, labevents, microbiologyevents, patients, prescriptions, procedures_icd, services, transfers 

ICU acquired data: If we want data from the ICU databases and only info during a patient's ICU stay then we want to look at the following tables: datetimeevents, inputevents_cv, inputevents_mv, notevents, outputevents, procedureevents_mv

We will primarily be looking at clinical notes and diagnoses so we will want to investigte the following tables:
1.) diagnoses_icd - https://mimic.physionet.org/mimictables/diagnoses_icd/
2.) prescriptions - https://mimic.physionet.org/mimictables/prescriptions/
3.) admissions (dead or alive time) - https://mimic.physionet.org/mimictables/admissions/
4.) noteevents (ICU clinicial notes) - https://mimic.physionet.org/mimictables/noteevents/

With regard to the notes there are a few types of notes: 
1.) discharge summary - a summary written by the physician (or possibly a team of physicians) at the time of discharge from the ICU. Note that in some cases, the patient may simply be discharged to the floor, or for observation. In the ICU, "discharged" doesn't necessarily mean "go home". The discharge summary is usually first, but not always (you may have to search for it.) 
2.) Radiology reports - reports from imaging procedures such as MRI, CT, and Ultrasounds.
3.) Nursing progress reports - day-by-day (or more frequent) notes from the nursing staff.

For more information on the MIMIC3 data we can refer to here: https://mimic.physionet.org

What we want to do: Use deep learning to predict patient diagnoses based off of clinical notes

I think that we should use spark and scala to clean our data and setup our training and test sets and maybe use tensorflow/keras for the deep learning because we might be more familiar with it than trying to do deep learning purely with spark. We might have more time to try out different layers in our network and tune parameters and such to get better results and have a better paper. 