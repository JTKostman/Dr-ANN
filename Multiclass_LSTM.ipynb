{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>LSTM for k-hot Encoded Multiclassification:</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from get_labels import get_labels\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Reshape\n",
    "from keras.layers import LSTM\n",
    "import subprocess;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Generate Random Training Lables:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Helper function to send notifications on Slack via Post CURL.\n",
    "'''\n",
    "def notify_slack(text):\n",
    "    subprocess.Popen('''curl -X POST --data-urlencode \"payload={'channel' : '#random', 'username': 'webhookbot', 'text':'''+ '\\'' + text + '\\'' + '''}\" https://hooks.slack.com/services/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''', shell=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Create the training labels\\ntrain_y = (np.random.randint(0,150,10000))\\ny = np.zeros((10000,150))\\nc = 0\\nfor i in train_y: \\n    y[c][i] = 1\\n    c = c+1\\ntrain_y = y.reshape(10000,1,150).reshape(10000,150)\\n\\n#Random Multi encoded training labels\\nr = np.random.rand(10000,150)\\nr[r <= 0.3] = False\\nr[r > 0.3] = True\\ntrain_y[r == False] = 1\\ntrain_y = train_y.reshape(10000,1,150)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Create the training labels\n",
    "train_y = (np.random.randint(0,150,10000))\n",
    "y = np.zeros((10000,150))\n",
    "c = 0\n",
    "for i in train_y: \n",
    "    y[c][i] = 1\n",
    "    c = c+1\n",
    "train_y = y.reshape(10000,1,150).reshape(10000,150)\n",
    "\n",
    "#Random Multi encoded training labels\n",
    "r = np.random.rand(10000,150)\n",
    "r[r <= 0.3] = False\n",
    "r[r > 0.3] = True\n",
    "train_y[r == False] = 1\n",
    "train_y = train_y.reshape(10000,1,150)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Load Training Labels: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2881: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "labels = get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_array = np.array([x for x in labels])\n",
    "labels_reshaped = labels_array.reshape(1851243, 1, 1070)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Generate Training X Data:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'NumpyArrayWrapper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a18dc1f8c8bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#train_x = np.array([np.random.rand(1, 1000)[0] for i in range(1851243)]).reshape(1851243,1,1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#import pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/mnt/cleaned_tfidf_counts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#train_x = pickle.load(open('/mnt/cleaned_tfidf_counts', 'rb'));\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# More user-friendly error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGLOBAL\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_global\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'NumpyArrayWrapper'"
     ]
    }
   ],
   "source": [
    "#Create the training x data\n",
    "#train_x = np.array([np.random.rand(1, 1000)[0] for i in range(1851243)]).reshape(1851243,1,1000)\n",
    "train_x = joblib.load(\"/mnt/cleaned_tfidf_reduced_420_morning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Load Samples: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1851243, 1000)\n",
      "(1851243, 1, 1000)\n"
     ]
    }
   ],
   "source": [
    "print (train_x.shape)\n",
    "train_x_reshaped = train_x.reshape(1851243,1,1000)\n",
    "print (train_x_reshaped.shape)\n",
    "#train_x = joblib.load(\"/mnt/saved_values/clean_tfidf_reduced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Create Train-Test Splits: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_x_reshaped, labels_reshaped, test_size=0.20, random_state=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-785f82019abf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xy_test1231.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "#from sklearn.externals import joblib\n",
    "joblib.dump((x_test, y_test), 'xy_test1.pkl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " New shapes:\n",
      "('x_train shape', (1480994, 1, 1000))\n",
      "('x_test shape', (370249, 1, 1000))\n",
      "('y_train shape', (1480994, 1, 1070))\n",
      "('y_test shape', (370249, 1, 1070))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "print (\"Raw Shapes:\")\n",
    "print(\"x_train_raw shape\", x_train_raw.shape)\n",
    "print(\"x_test_raw shape\", x_test_raw.shape)\n",
    "\n",
    "print(\"y_train_raw shape\", y_train_raw.shape)\n",
    "print(\"y_test_raw shape\", y_test_raw.shape)\n",
    "\n",
    "# split causes 1480994 training vs 370249 testing samples\n",
    "\n",
    "x_train = x_train_raw.reshape(1480994, 1, 1000)\n",
    "x_test = x_test_raw.reshape(370249, 1, 1000)\n",
    "\n",
    "y_train = y_train_raw.reshape(1480994, 1, 1070)\n",
    "y_test = y_test_raw.reshape(370249, 1, 1070)\n",
    "\"\"\"\n",
    "\n",
    "print (\"\\n New shapes:\")\n",
    "print(\"x_train shape\", x_train.shape)\n",
    "print(\"x_test shape\", x_test.shape)\n",
    "\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create A Sample Query to Predict On:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the sample query \n",
    "sample = train_x[0].reshape(1,1,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create Multiclass Loss Function:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Our custom loss function\n",
    "def multiclass_loss(y_true, y_pred):\n",
    "    EPS = 1e-5\n",
    "    y_pred = K.clip(y_pred, EPS, 1 - EPS)\n",
    "    return -K.mean((1 - y_true) * K.log(1 - y_pred) + y_true * K.log(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Instantiate Parameters for LSTM:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Our inputs for our model\n",
    "shape = x_train.shape[2]\n",
    "num_classes = 1070"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create and Compile LSTM:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to create and compile our model\n",
    "def create_model(shape,num_classes):\n",
    "    print (type(shape), type(num_classes))\n",
    "    print (shape, num_classes) # (None,shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(output_dim=32, input_shape=(None, shape), return_sequences=True))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss=multiclass_loss, optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train LSTM</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<type 'int'>, <type 'int'>)\n",
      "(1000, 1070)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python2.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=32, return_sequences=True, input_shape=(None, 100...)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1480994/1480994 [==============================] - 137s - loss: 0.0458 - acc: 0.0120   \n",
      "Epoch 2/10\n",
      "1480994/1480994 [==============================] - 140s - loss: 0.0345 - acc: 0.0193   \n",
      "Epoch 3/10\n",
      "1480994/1480994 [==============================] - 140s - loss: 0.0340 - acc: 0.0235   \n",
      "Epoch 4/10\n",
      "1480994/1480994 [==============================] - 139s - loss: 0.0338 - acc: 0.0244   \n",
      "Epoch 5/10\n",
      "1480994/1480994 [==============================] - 137s - loss: 0.0337 - acc: 0.0248   \n",
      "Epoch 6/10\n",
      "1480994/1480994 [==============================] - 139s - loss: 0.0336 - acc: 0.0249   \n",
      "Epoch 7/10\n",
      "1480994/1480994 [==============================] - 137s - loss: 0.0335 - acc: 0.0249   \n",
      "Epoch 8/10\n",
      "1480994/1480994 [==============================] - 138s - loss: 0.0335 - acc: 0.0250   \n",
      "Epoch 9/10\n",
      "1480994/1480994 [==============================] - 141s - loss: 0.0335 - acc: 0.0250   \n",
      "Epoch 10/10\n",
      "1480994/1480994 [==============================] - 138s - loss: 0.0334 - acc: 0.0251   \n"
     ]
    }
   ],
   "source": [
    "#Creating and training our model\n",
    "model = create_model(shape, num_classes)\n",
    "history = model.fit(x_train, y_train,\n",
    "              batch_size=100, epochs=10,\n",
    "              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#notify_slack('finished lstm');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Save LSTM Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model   #save_model requires h5py, need to pip install h5py\n",
    "model.save('khot_LSTM_1353.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load LSTM With Custom Loss Function:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading our model with our custom loss function\n",
    "model = load_model('khot_LSTM_1353.h5', custom_objects={\"multiclass_loss\":multiclass_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Obtain Prediction of Sample Query:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Our top prediction is: ', 702, '\\n')\n",
      "Indices of Top 15 predictions:\n",
      "(array([702, 782,  89, 305, 307, 851, 798,  93, 663,  84, 878, 590,  95,\n",
      "       499, 349]), '\\n')\n",
      "Indices where we have a 1:\n",
      "()\n",
      "[[  0  26]\n",
      " [  0  79]\n",
      " [  0  84]\n",
      " [  0  89]\n",
      " [  0 294]\n",
      " [  0 307]\n",
      " [  0 340]\n",
      " [  0 394]\n",
      " [  0 565]\n",
      " [  0 617]\n",
      " [  0 666]\n",
      " [  0 702]\n",
      " [  0 851]\n",
      " [  0 913]\n",
      " [  0 924]]\n",
      "[ 0.93998671  0.58149642  0.57313067  0.5652886   0.49347237  0.4805845\n",
      "  0.44362068  0.40229726  0.38860407  0.36885086  0.27008268  0.23909026\n",
      "  0.23009497  0.21920893  0.21321656]\n",
      "11.5486\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(sample)[0][0]\n",
    "#print(pred)\n",
    "all_ones = np.argwhere(y_train[0] == 1);\n",
    "print('Our top prediction is: ',np.argmax(pred),\"\\n\")\n",
    "print(\"Indices of Top \" + str(len(all_ones)) + \" predictions:\")\n",
    "top3 = pred.argsort()[-1 * len(all_ones):][::-1]\n",
    "print(top3,\"\\n\")\n",
    "print(\"Indices where we have a 1:\")\n",
    "print()\n",
    "#print(pred)\n",
    "#print(min(pred))\n",
    "#print(max(pred))\n",
    "#print(np.mean(pred))\n",
    "print(all_ones)\n",
    "print(-1 * np.sort(-1 * pred)[0:len(all_ones)]);\n",
    "print(np.sum(pred));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
