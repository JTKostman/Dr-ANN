{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>LSTM for k-hot Encoded Multiclassification:</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from get_labels import get_labels\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Reshape, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import *;\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint;\n",
    "\n",
    "import urllib2;\n",
    "import json;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Generate Random Training Lables:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Helper function to send notifications on Slack via Post CURL.\n",
    "'''\n",
    "def notify_slack(message):\n",
    "    url = 'https://hooks.slack.com/services/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';\n",
    "    post_fields = json.dumps({'channel' : '#random', 'username': 'webhookbot', 'text': message});\n",
    "\n",
    "    request = urllib2.Request(url, post_fields);\n",
    "    response = urllib2.urlopen(request)\n",
    "    read_val = response.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Create the training labels\\ntrain_y = (np.random.randint(0,150,10000))\\ny = np.zeros((10000,150))\\nc = 0\\nfor i in train_y: \\n    y[c][i] = 1\\n    c = c+1\\ntrain_y = y.reshape(10000,1,150).reshape(10000,150)\\n\\n#Random Multi encoded training labels\\nr = np.random.rand(10000,150)\\nr[r <= 0.3] = False\\nr[r > 0.3] = True\\ntrain_y[r == False] = 1\\ntrain_y = train_y.reshape(10000,1,150)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Create the training labels\n",
    "train_y = (np.random.randint(0,150,10000))\n",
    "y = np.zeros((10000,150))\n",
    "c = 0\n",
    "for i in train_y: \n",
    "    y[c][i] = 1\n",
    "    c = c+1\n",
    "train_y = y.reshape(10000,1,150).reshape(10000,150)\n",
    "\n",
    "#Random Multi encoded training labels\n",
    "r = np.random.rand(10000,150)\n",
    "r[r <= 0.3] = False\n",
    "r[r > 0.3] = True\n",
    "train_y[r == False] = 1\n",
    "train_y = train_y.reshape(10000,1,150)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Load Training Labels: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2881: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "labels = get_labels()\n",
    "notify_slack('Got labels');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_array = np.array([x for x in labels])\n",
    "labels_reshaped = labels_array.reshape(1851243, 1, 1070)\n",
    "notify_slack('Labeles Reshaped');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Generate Training X Data:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the training x data\n",
    "#train_x = np.array([np.random.rand(1, 1000)[0] for i in range(1851243)]).reshape(1851243,1,1000)\n",
    "train_x = joblib.load(\"/mnt/cleaned_tfidf_reduced_420_morning\")\n",
    "notify_slack('Loaded Train X');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Load Samples: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1851243, 1000)\n",
      "(1851243, 1, 1000)\n"
     ]
    }
   ],
   "source": [
    "print (train_x.shape)\n",
    "train_x_reshaped = train_x.reshape(1851243,1,1000)\n",
    "print (train_x_reshaped.shape)\n",
    "#train_x = joblib.load(\"/mnt/saved_values/clean_tfidf_reduced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Create Train-Test Splits: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_x_reshaped, labels_reshaped, test_size=0.20, random_state=1024)\n",
    "notify_slack('Obtained Train Test Split');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_x\n",
    "del labels_array\n",
    "del labels_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-785f82019abf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xy_test1231.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "#from sklearn.externals import joblib\n",
    "joblib.dump((x_test, y_test), 'xy_test1.pkl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " New shapes:\n",
      "('x_train shape', (1480994, 1, 1000))\n",
      "('x_test shape', (370249, 1, 1000))\n",
      "('y_train shape', (1480994, 1, 1070))\n",
      "('y_test shape', (370249, 1, 1070))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "print (\"Raw Shapes:\")\n",
    "print(\"x_train_raw shape\", x_train_raw.shape)\n",
    "print(\"x_test_raw shape\", x_test_raw.shape)\n",
    "\n",
    "print(\"y_train_raw shape\", y_train_raw.shape)\n",
    "print(\"y_test_raw shape\", y_test_raw.shape)\n",
    "\n",
    "# split causes 1480994 training vs 370249 testing samples\n",
    "\n",
    "x_train = x_train_raw.reshape(1480994, 1, 1000)\n",
    "x_test = x_test_raw.reshape(370249, 1, 1000)\n",
    "\n",
    "y_train = y_train_raw.reshape(1480994, 1, 1070)\n",
    "y_test = y_test_raw.reshape(370249, 1, 1070)\n",
    "\"\"\"\n",
    "\n",
    "print (\"\\n New shapes:\")\n",
    "print(\"x_train shape\", x_train.shape)\n",
    "print(\"x_test shape\", x_test.shape)\n",
    "\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create A Sample Query to Predict On:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the sample query \n",
    "#sample = train_x[0].reshape(1,1,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create Multiclass Loss Function:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Our custom loss function\n",
    "def multiclass_loss(y_true, y_pred):\n",
    "    EPS = 1e-5\n",
    "    y_pred = K.clip(y_pred, EPS, 1 - EPS)\n",
    "    return -K.mean((1 - y_true) * K.log(1 - y_pred) + y_true * K.log(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Instantiate Parameters for LSTM:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Our inputs for our model\n",
    "shape = x_train.shape[2]\n",
    "num_classes = 1070"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create and Compile LSTM:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to create and compile our model\n",
    "def create_model(shape,num_classes):\n",
    "    print (type(shape), type(num_classes))\n",
    "    print (shape, num_classes) # (None,shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(output_dim=128, input_shape=(None, shape), return_sequences=True));\n",
    "    #model.add(LSTM(output_dim=32, input_shape=(None, shape), return_sequences=True));\n",
    "    model.add(Dropout(rate=0.1));\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='tanh'));\n",
    "    \n",
    "    #opt = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    opt = SGD(lr=0.001, decay=0.1);\n",
    "    \n",
    "    filepath = 'model_checkpoint'\n",
    "\n",
    "    model.compile(loss=multiclass_loss, optimizer=opt, metrics=['accuracy', 'mse', 'mae']);\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    \n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    \n",
    "    return model, callbacks_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train LSTM</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<type 'int'>, <type 'int'>)\n",
      "(1000, 1070)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python2.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=128, return_sequences=True, input_shape=(None, 100...)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1480994/1480994 [==============================] - 176s - loss: 0.0869 - acc: 0.0058 - mean_squared_error: 0.0117 - mean_absolute_error: 0.0158   \n",
      "Epoch 2/10\n",
      "    128/1480994 [..............................] - ETA: 2179s - loss: 0.0849 - acc: 0.0078 - mean_squared_error: 0.0117 - mean_absolute_error: 0.0158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:389: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1444736/1480994 [============================>.] - ETA: 4s - loss: 0.0846 - acc: 0.0073 - mean_squared_error: 0.0117 - mean_absolute_error: 0.0158"
     ]
    }
   ],
   "source": [
    "#Creating and training our model\n",
    "model, callbacks_list = create_model(shape, num_classes)\n",
    "notify_slack('Obtained LSTM Model and starting training');\n",
    "history = model.fit(x_train, y_train,\n",
    "              batch_size=128, epochs=10,\n",
    "              verbose = 1, callbacks=callbacks_list)\n",
    "notify_slack('Completed LSTM Model on 100 epochs');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Save LSTM Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model   #save_model requires h5py, need to pip install h5py\n",
    "model.save('khot_LSTM_1132.h5') \n",
    "notify_slack('Saved LSTM Model');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load LSTM With Custom Loss Function:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading our model with our custom loss function\n",
    "model = load_model('khot_LSTM_1353.h5', custom_objects={\"multiclass_loss\":multiclass_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Obtain Prediction of Sample Query:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Our top prediction is: ', 702, '\\n')\n",
      "Indices of Top 15 predictions:\n",
      "(array([702, 782,  89, 305, 307, 851, 798,  93, 663,  84, 878, 590,  95,\n",
      "       499, 349]), '\\n')\n",
      "Indices where we have a 1:\n",
      "()\n",
      "[[  0  26]\n",
      " [  0  79]\n",
      " [  0  84]\n",
      " [  0  89]\n",
      " [  0 294]\n",
      " [  0 307]\n",
      " [  0 340]\n",
      " [  0 394]\n",
      " [  0 565]\n",
      " [  0 617]\n",
      " [  0 666]\n",
      " [  0 702]\n",
      " [  0 851]\n",
      " [  0 913]\n",
      " [  0 924]]\n",
      "[ 0.93998671  0.58149642  0.57313067  0.5652886   0.49347237  0.4805845\n",
      "  0.44362068  0.40229726  0.38860407  0.36885086  0.27008268  0.23909026\n",
      "  0.23009497  0.21920893  0.21321656]\n",
      "11.5486\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(sample)[0][0]\n",
    "#print(pred)\n",
    "all_ones = np.argwhere(y_train[0] == 1);\n",
    "print('Our top prediction is: ',np.argmax(pred),\"\\n\")\n",
    "print(\"Indices of Top \" + str(len(all_ones)) + \" predictions:\")\n",
    "top3 = pred.argsort()[-1 * len(all_ones):][::-1]\n",
    "print(top3,\"\\n\")\n",
    "print(\"Indices where we have a 1:\")\n",
    "print()\n",
    "#print(pred)\n",
    "#print(min(pred))\n",
    "#print(max(pred))\n",
    "#print(np.mean(pred))\n",
    "print(all_ones)\n",
    "print(-1 * np.sort(-1 * pred)[0:len(all_ones)]);\n",
    "print(np.sum(pred));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
