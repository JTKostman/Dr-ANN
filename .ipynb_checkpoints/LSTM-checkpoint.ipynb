{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Build LSTM model:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSTM_model(shape,neurons,output):\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, input_shape=shape, return_sequences=True))\n",
    "    model.add(Dense(output))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    #Optimizer\n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    \n",
    "    #Compile model \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    return model \n",
    "\n",
    "output = 1\n",
    "neurons = 128 #also known as blocks\n",
    "shape = (2000000,40000)\n",
    "LSTM = LSTM_model(shape,neurons,output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Train LSTM and save model:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(train_x, train_y,epochs,batches):\n",
    "    \n",
    "    model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batches, verbose=2)\n",
    "    #Save partly trained model\n",
    "    model.save('trained_model.h5')\n",
    "    \n",
    "epochs = 100\n",
    "batches = 200\n",
    "train_model(train_x,train_y,epochs,batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Load saved model:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(filename):\n",
    "    \n",
    "    #Load model\n",
    "    model = load_model(filename)\n",
    "    return model\n",
    "\n",
    "filename = 'trained_model.h5'\n",
    "model = load_model(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Predict model with test ICD-9 Codes</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(test_x):\n",
    "    \n",
    "    #Query the model\n",
    "    prediction = model.predict(self, test_x, batch_size=batches, verbose=0)\n",
    "    return prediction \n",
    "\n",
    "prediction = predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Confusion Matrix Statistics:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All together \n",
    "def LSTM_model(shape):\n",
    "    \n",
    "    print('Building model...')\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=shape, return_sequences=True))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    #Optimizer\n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    \n",
    "    #Compile model \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    return model \n",
    "\n",
    "def train_model(train_x, train_y,epochs,batches)\n",
    "    model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batches, verbose=2)\n",
    "    #Save partly trained model\n",
    "    model.save('trained_model.h5')\n",
    "\n",
    "    \n",
    "        \n",
    "epochs = 100\n",
    "batches = 200\n",
    "train_model(train_x,train_y,epochs,batches)\n",
    "\n",
    "def load_model(filename):\n",
    "    #Load model\n",
    "    model = load_model(filename)\n",
    "    return model\n",
    "\n",
    "filename = 'trained_model.h5'\n",
    "load_model(filename)\n",
    "\n",
    "def predict(test_x)\n",
    "    #Query the model\n",
    "    prediction = model.predict(self, test_x, batch_size=batches, verbose=0)\n",
    "    return prediction \n",
    "\n",
    "prediction = predict(test_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
